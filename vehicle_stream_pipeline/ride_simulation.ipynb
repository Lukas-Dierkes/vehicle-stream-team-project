{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from datetime import datetime as dt\n",
    "from re import M\n",
    "import ast\n",
    "\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import truncnorm\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>number_of_passenger</th>\n",
       "      <th>price_operations</th>\n",
       "      <th>price_offer</th>\n",
       "      <th>price_payed</th>\n",
       "      <th>free_ride</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>pickup_address</th>\n",
       "      <th>dropoff_address</th>\n",
       "      <th>state</th>\n",
       "      <th>created_from_offer</th>\n",
       "      <th>created_at</th>\n",
       "      <th>scheduled_to</th>\n",
       "      <th>dispatched_at</th>\n",
       "      <th>pickup_arrival_time</th>\n",
       "      <th>arriving_push</th>\n",
       "      <th>vehicle_arrived_at</th>\n",
       "      <th>earliest_pickup_expectation</th>\n",
       "      <th>pickup_first_eta</th>\n",
       "      <th>pickup_eta</th>\n",
       "      <th>pickup_at</th>\n",
       "      <th>dropoff_first_eta</th>\n",
       "      <th>dropoff_eta</th>\n",
       "      <th>dropoff_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>arrival_deviation</th>\n",
       "      <th>waiting_time</th>\n",
       "      <th>boarding_time</th>\n",
       "      <th>ride_time</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>shortest_ridetime</th>\n",
       "      <th>delay</th>\n",
       "      <th>longer_route_factor</th>\n",
       "      <th>arrival_indicator</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_puenktlichkeit</th>\n",
       "      <th>rating_sauberkeit</th>\n",
       "      <th>rating_fahrer</th>\n",
       "      <th>rating_find_modstop</th>\n",
       "      <th>rating_other_comments</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>cancellation_comment</th>\n",
       "      <th>bahn_card_number</th>\n",
       "      <th>year_card_type</th>\n",
       "      <th>year_card_number</th>\n",
       "      <th>canceled_at</th>\n",
       "      <th>rating_question_one</th>\n",
       "      <th>rating_question_two</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5727475e-8224-4302-9228-c92b9d4a5220</td>\n",
       "      <td>f8ff0526-887a-4e48-ad96-977e12fd70c1</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>11009</td>\n",
       "      <td>6004</td>\n",
       "      <td>completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-06-30 23:12:47</td>\n",
       "      <td>2021-07-01 07:30:00</td>\n",
       "      <td>2021-07-01 07:22:00</td>\n",
       "      <td>637.0</td>\n",
       "      <td>2021-07-01 07:29:37</td>\n",
       "      <td>2021-07-01 07:32:37</td>\n",
       "      <td>2021-07-01 07:25:00</td>\n",
       "      <td>2021-07-01 07:33:55</td>\n",
       "      <td>2021-07-01 07:34:07</td>\n",
       "      <td>2021-07-01 07:33:08</td>\n",
       "      <td>2021-07-01 07:44:27</td>\n",
       "      <td>2021-07-01 07:44:39</td>\n",
       "      <td>2021-07-01 07:44:44</td>\n",
       "      <td>2021-11-03 16:00:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18fec0a6-b7ba-442b-8472-04bdb6ba1b86</td>\n",
       "      <td>51e1a1a8-995c-488c-84ce-3789e46f0417</td>\n",
       "      <td>3575.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>BAHN_CARD</td>\n",
       "      <td>2007</td>\n",
       "      <td>3025</td>\n",
       "      <td>canceled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-06-30 22:51:53</td>\n",
       "      <td>2021-07-01 08:50:00</td>\n",
       "      <td>2021-07-01 08:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-01 08:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-01 08:16:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                               user_id  \\\n",
       "0  5727475e-8224-4302-9228-c92b9d4a5220  f8ff0526-887a-4e48-ad96-977e12fd70c1   \n",
       "1  18fec0a6-b7ba-442b-8472-04bdb6ba1b86  51e1a1a8-995c-488c-84ce-3789e46f0417   \n",
       "\n",
       "   distance  number_of_passenger  price_operations  price_offer  price_payed  \\\n",
       "0    5483.0                  1.0              4.65         4.65          0.0   \n",
       "1    3575.0                  1.0              0.00         2.77          0.0   \n",
       "\n",
       "   free_ride payment_type  pickup_address  dropoff_address      state  \\\n",
       "0      False     STANDARD           11009             6004  completed   \n",
       "1      False    BAHN_CARD            2007             3025   canceled   \n",
       "\n",
       "   created_from_offer           created_at         scheduled_to  \\\n",
       "0                 NaN  2021-06-30 23:12:47  2021-07-01 07:30:00   \n",
       "1                 NaN  2021-06-30 22:51:53  2021-07-01 08:50:00   \n",
       "\n",
       "         dispatched_at  pickup_arrival_time        arriving_push  \\\n",
       "0  2021-07-01 07:22:00                637.0  2021-07-01 07:29:37   \n",
       "1  2021-07-01 08:42:00                  NaN                  NaN   \n",
       "\n",
       "    vehicle_arrived_at earliest_pickup_expectation     pickup_first_eta  \\\n",
       "0  2021-07-01 07:32:37         2021-07-01 07:25:00  2021-07-01 07:33:55   \n",
       "1                  NaN         2021-07-01 08:45:00                  NaN   \n",
       "\n",
       "            pickup_eta            pickup_at    dropoff_first_eta  \\\n",
       "0  2021-07-01 07:34:07  2021-07-01 07:33:08  2021-07-01 07:44:27   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "\n",
       "           dropoff_eta           dropoff_at           updated_at  \\\n",
       "0  2021-07-01 07:44:39  2021-07-01 07:44:44  2021-11-03 16:00:44   \n",
       "1                  NaN                  NaN  2021-07-01 08:16:03   \n",
       "\n",
       "   arrival_deviation  waiting_time  boarding_time  ride_time  trip_time  \\\n",
       "0                0.0         457.0           31.0      696.0     1153.0   \n",
       "1                NaN           NaN            NaN        NaN        NaN   \n",
       "\n",
       "   shortest_ridetime  delay  longer_route_factor arrival_indicator  rating  \\\n",
       "0              658.0  495.0                 1.06              None     NaN   \n",
       "1              429.0    NaN                  NaN              None     NaN   \n",
       "\n",
       "   rating_puenktlichkeit  rating_sauberkeit  rating_fahrer  \\\n",
       "0                    NaN                NaN            NaN   \n",
       "1                    NaN                NaN            NaN   \n",
       "\n",
       "   rating_find_modstop  rating_other_comments cancellation_reason  \\\n",
       "0                  NaN                    NaN                 NaN   \n",
       "1                  NaN                    NaN                 NaN   \n",
       "\n",
       "   cancellation_comment bahn_card_number year_card_type year_card_number  \\\n",
       "0                   NaN              NaN            NaN              NaN   \n",
       "1                   NaN              NaN            NaN              NaN   \n",
       "\n",
       "  canceled_at rating_question_one rating_question_two  index  \n",
       "0         NaN                 NaN                 NaN    NaN  \n",
       "1         NaN                 NaN                 NaN    NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = git.Repo(\".\", search_parent_directories=True).git.rev_parse(\n",
    "    \"--show-toplevel\"\n",
    ")\n",
    "df = pd.read_csv(f\"{repo}/data/cleaning/cleaned_1658850129.csv\") \n",
    "df_stops = pd.read_excel(\n",
    "    f\"{repo}/data/other/MoDstops+Preismodell.xlsx\", sheet_name=\"MoDstops\"\n",
    ")\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MoDStop Id</th>\n",
       "      <th>MoDStop Name</th>\n",
       "      <th>MoDStop Lat</th>\n",
       "      <th>MoDStop Long</th>\n",
       "      <th>MoDStop Adresse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Mandelgasse</td>\n",
       "      <td>49.351780</td>\n",
       "      <td>8.129000</td>\n",
       "      <td>Seilerbahn 1, 67433 Neustadt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Hauptfeuerwache</td>\n",
       "      <td>49.353733</td>\n",
       "      <td>8.131552</td>\n",
       "      <td>Lindenstraße 11, 67433 Neustadt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MoDStop Id     MoDStop Name  MoDStop Lat  MoDStop Long  \\\n",
       "0        1001      Mandelgasse    49.351780      8.129000   \n",
       "1        1002  Hauptfeuerwache    49.353733      8.131552   \n",
       "\n",
       "                   MoDStop Adresse  \n",
       "0     Seilerbahn 1, 67433 Neustadt  \n",
       "1  Lindenstraße 11, 67433 Neustadt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stops = pd.read_excel(\n",
    "    f\"{repo}/data/other/MoDstops+Preismodell.xlsx\", sheet_name=\"MoDstops\"\n",
    ")\n",
    "df_stops.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start #</th>\n",
       "      <th>Start Name</th>\n",
       "      <th>Ende #</th>\n",
       "      <th>Ende Name</th>\n",
       "      <th>Route [m]</th>\n",
       "      <th>Luftlinie [m]</th>\n",
       "      <th>VRN-eTarif\\nohne Bahncard</th>\n",
       "      <th>VRN-eTarif\\nmit BahnCard</th>\n",
       "      <th>Qualitätszuschlag</th>\n",
       "      <th>MoD-Fahrpreis \\nohne BahnCard</th>\n",
       "      <th>MoD-Fahrpreis\\n mit Bahncard</th>\n",
       "      <th>0.12680550240634963</th>\n",
       "      <th>0.07159177456207169</th>\n",
       "      <th>0.18042226487523982</th>\n",
       "      <th>0.5159630940478845</th>\n",
       "      <th>0.2894135567402895</th>\n",
       "      <th>0.72936660268714</th>\n",
       "      <th>price_mod</th>\n",
       "      <th>price_mod_2pers</th>\n",
       "      <th>price_mod_3pers</th>\n",
       "      <th>price_mod_4pers</th>\n",
       "      <th>price_bahncard</th>\n",
       "      <th>price_bahncard_2pers</th>\n",
       "      <th>price_bahncard_3pers</th>\n",
       "      <th>price_bahncard_4pers</th>\n",
       "      <th>price_vrn_surcharge</th>\n",
       "      <th>price_vrn_surcharge_2pers</th>\n",
       "      <th>price_vrn_surcharge_3pers</th>\n",
       "      <th>price_vrn_surcharge_4pers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Mandelgasse</td>\n",
       "      <td>1002</td>\n",
       "      <td>Hauptfeuerwache</td>\n",
       "      <td>366</td>\n",
       "      <td>285</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.55</td>\n",
       "      <td>4.275</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.725</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.865</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.625</td>\n",
       "      <td>3.94</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Mandelgasse</td>\n",
       "      <td>1003</td>\n",
       "      <td>Kindergarten St. Marien</td>\n",
       "      <td>994</td>\n",
       "      <td>586</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.55</td>\n",
       "      <td>4.275</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.725</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.865</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.625</td>\n",
       "      <td>3.94</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start #   Start Name  Ende #                Ende Name  Route [m]  \\\n",
       "0     1001  Mandelgasse    1002          Hauptfeuerwache        366   \n",
       "1     1001  Mandelgasse    1003  Kindergarten St. Marien        994   \n",
       "\n",
       "   Luftlinie [m]  VRN-eTarif\\nohne Bahncard  VRN-eTarif\\nmit BahnCard  \\\n",
       "0            285                       1.65                      1.24   \n",
       "1            586                       1.65                      1.24   \n",
       "\n",
       "   Qualitätszuschlag  MoD-Fahrpreis \\nohne BahnCard  \\\n",
       "0                0.9                           2.55   \n",
       "1                0.9                           2.55   \n",
       "\n",
       "   MoD-Fahrpreis\\n mit Bahncard  0.12680550240634963 0.07159177456207169  \\\n",
       "0                          2.14             0.160784                 NaN   \n",
       "1                          2.14             0.160784                 NaN   \n",
       "\n",
       "   0.18042226487523982  0.5159630940478845  0.2894135567402895  \\\n",
       "0                  NaN            0.647059                 NaN   \n",
       "1                  NaN            0.647059                 NaN   \n",
       "\n",
       "   0.72936660268714  price_mod  price_mod_2pers  price_mod_3pers  \\\n",
       "0               NaN       2.55            4.275              6.0   \n",
       "1               NaN       2.55            4.275              6.0   \n",
       "\n",
       "   price_mod_4pers  price_bahncard  price_bahncard_2pers  \\\n",
       "0            7.725            2.14                 3.865   \n",
       "1            7.725            2.14                 3.865   \n",
       "\n",
       "   price_bahncard_3pers  price_bahncard_4pers  price_vrn_surcharge  \\\n",
       "0                  5.18                   6.7                  0.9   \n",
       "1                  5.18                   6.7                  0.9   \n",
       "\n",
       "   price_vrn_surcharge_2pers  price_vrn_surcharge_3pers  \\\n",
       "0                      2.625                       3.94   \n",
       "1                      2.625                       3.94   \n",
       "\n",
       "   price_vrn_surcharge_4pers  \n",
       "0                       5.46  \n",
       "1                       5.46  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_routes = pd.read_excel(\n",
    "    f\"{repo}/data/other/MoDstops+Preismodell.xlsx\", sheet_name=\"Liste 2022\"\n",
    ")\n",
    "df_routes.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getdistribution()\n",
    "- help function that returns a probability distribution for continous variables based on mean & standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdistribution(data, column, min=None, max=None):\n",
    "    # distribution over scheduled rides\n",
    "    mean = data[column].median() # use median to better deal with outlier\n",
    "    std = data[column].std()\n",
    "    if min==None: \n",
    "        a = data[column].min() # min value\n",
    "    else:\n",
    "        a = min \n",
    "    if max==None:\n",
    "        b = data[column].max() # max value\n",
    "    else:\n",
    "        b = max\n",
    "    return stats.truncnorm((a - mean) / std, (b - mean) / std, loc=mean, scale=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Old but gold \n",
    "\n",
    "\n",
    "# ##### TODO: Check in the end if too many rides, which are too short or are not likely enough \n",
    "# # Check that no same start and stop address \n",
    "\n",
    "\n",
    "# def generateRoute(oldRides, newRides, ridestops, routes):\n",
    "#     # based on analysis of rides we distinguish between workdays (Monday till Friday noon) and weekend (Friday noon till Sunday)\n",
    "#     newRideStops = pd.DataFrame(newRides[['scheduled_to', 'pickup_address', 'dropoff_address']], columns=['scheduled_to', 'pickup_address', 'dropoff_address'])\n",
    "#     newRideStops['day'] = newRideStops['scheduled_to'].apply(lambda x: dt.weekday(x))\n",
    "#     newRideStops['hour'] = newRideStops['scheduled_to'].apply(lambda x: x.hour)\n",
    "#     newRideStops['workday'] = np.where(\n",
    "#         (\n",
    "#             newRideStops['day'].isin([0,1,2,3,4]) # 0 = Monday, 6 = Sunday\n",
    "#             & ~(\n",
    "#                     (newRideStops['day'] == 4) \n",
    "#                     & (newRideStops['hour'] > 13)\n",
    "#             )\n",
    "#         ),\n",
    "#         True,\n",
    "#         False\n",
    "#     )\n",
    "\n",
    "#     oldRidestops = pd.DataFrame(oldRides[['state', 'scheduled_to', 'pickup_address', 'dropoff_address']], columns=['state', 'scheduled_to', 'pickup_address', 'dropoff_address'])\n",
    "#     oldRidestops['scheduled_to'] = pd.to_datetime(oldRidestops['scheduled_to'])\n",
    "#     oldRidestops['day'] = oldRidestops['scheduled_to'].apply(lambda x: dt.weekday(x))\n",
    "#     oldRidestops['hour'] = oldRidestops['scheduled_to'].apply(lambda x: x.hour)\n",
    "#     oldRidestops['workday'] = np.where(\n",
    "#         (\n",
    "#             oldRidestops['day'].isin([0,1,2,3,4]) # 0 = Monday, 6 = Sunday\n",
    "#             & ~(\n",
    "#                     (oldRidestops['day'] == 4) \n",
    "#                     & (oldRidestops['hour'] > 13)\n",
    "#             )\n",
    "#         ),\n",
    "#         True,\n",
    "#         False\n",
    "#     )\n",
    "#     workdayOldRides = oldRidestops[(oldRidestops['workday']==True) & (oldRidestops['state']=='completed')]\n",
    "#     weekendOldRides = oldRidestops[(oldRidestops['workday']==False) & (oldRidestops['state']=='completed')]\n",
    "\n",
    "#     # generate ridestops\n",
    "#     for h in [0] + list(range(7,24)): # rides start between 7:00 and 0:59\n",
    "#         # timeframe used to get ridestop distribution\n",
    "#         if h in [23,0]:\n",
    "#             timeframe = [22,23,0]\n",
    "#         elif h == 7:\n",
    "#             timeframe = [7,8,9]\n",
    "#         else:\n",
    "#             timeframe = list(range(h-1,h+2))\n",
    "\n",
    "#         ##### workday ridestop distribution #####\n",
    "#         # get pickup ridestop distribution of rides on workdays, which are in a +/- 1h timeframe around the planned departure; And add not considered ridestops with minimal frequency count of used stops\n",
    "#         distPickupWorkday = workdayOldRides[(workdayOldRides['hour'].isin(timeframe))]['pickup_address'].value_counts().rename_axis('pickup_address').reset_index(name='counts')\n",
    "#         distPickupWorkday = distPickupWorkday.merge(ridestops['MoDStop Id'], left_on='pickup_address', how='outer', right_on='MoDStop Id')\n",
    "#         distPickupWorkday['pickup_address'] = distPickupWorkday['MoDStop Id']\n",
    "#         distPickupWorkday = distPickupWorkday.fillna(distPickupWorkday['counts'].min())\n",
    "#         distPickupWorkday['probabilities'] = (distPickupWorkday.counts / distPickupWorkday.counts.sum())\n",
    "#         # get dropoff ridestop distribution of rides on workdays, which are in a +/- 1h timeframe around the planned departure; And add not considered ridestops with minimal frequency count of used stops\n",
    "#         distDropoffWorkday = workdayOldRides[(workdayOldRides['hour'].isin(timeframe))]['dropoff_address'].value_counts().rename_axis('dropoff_address').reset_index(name='counts')\n",
    "#         distDropoffWorkday = distDropoffWorkday.merge(ridestops['MoDStop Id'], left_on='dropoff_address', how='outer', right_on='MoDStop Id')\n",
    "#         distDropoffWorkday['dropoff_address'] = distDropoffWorkday['MoDStop Id']\n",
    "#         distDropoffWorkday = distDropoffWorkday.fillna(distDropoffWorkday['counts'].min())\n",
    "#         distDropoffWorkday['probabilities'] = (distDropoffWorkday.counts / distDropoffWorkday.counts.sum())\n",
    "\n",
    "#         ##### weekend ridestop distribution #####\n",
    "#         # get pickup ridestop distribution of rides on workdays, which are in a +/- 1h timeframe around the planned departure; And add not considered ridestops with minimal frequency count of used stops\n",
    "#         distPickupWeekend = weekendOldRides[(weekendOldRides['hour'].isin(timeframe))]['pickup_address'].value_counts().rename_axis('pickup_address').reset_index(name='counts')\n",
    "#         distPickupWeekend = distPickupWeekend.merge(ridestops['MoDStop Id'], left_on='pickup_address', how='outer', right_on='MoDStop Id')\n",
    "#         distPickupWeekend['pickup_address'] = distPickupWeekend['MoDStop Id']\n",
    "#         distPickupWeekend = distPickupWeekend.fillna(distPickupWeekend['counts'].min())\n",
    "#         distPickupWeekend['probabilities'] = (distPickupWeekend.counts / distPickupWeekend.counts.sum())\n",
    "#         # get dropoff ridestop distribution of rides on workdays, which are in a +/- 1h timeframe around the planned departure; And add not considered ridestops with minimal frequency count of used stops\n",
    "#         distDropoffWeekend = weekendOldRides[(weekendOldRides['hour'].isin(timeframe))]['dropoff_address'].value_counts().rename_axis('dropoff_address').reset_index(name='counts')\n",
    "#         distDropoffWeekend = distDropoffWeekend.merge(ridestops['MoDStop Id'], left_on='dropoff_address', how='outer', right_on='MoDStop Id')\n",
    "#         distDropoffWeekend['dropoff_address'] = distDropoffWeekend['MoDStop Id']\n",
    "#         distDropoffWeekend = distDropoffWeekend.fillna(distDropoffWeekend['counts'].min())\n",
    "#         distDropoffWeekend['probabilities'] = (distDropoffWeekend.counts / distDropoffWeekend.counts.sum())\n",
    "\n",
    "#         # for all new rides planned at time h choose ridestops based on the distributions\n",
    "#         # pickup_address:\n",
    "#         newRideStops['pickup_address'] = np.where(\n",
    "#             (newRideStops['workday'] == True)\n",
    "#             & (newRideStops['hour'] == h),\n",
    "#             np.random.choice(distPickupWorkday['pickup_address'], p=distPickupWorkday['probabilities']),\n",
    "#             np.where(\n",
    "#                 (newRideStops['workday'] == False)\n",
    "#                 & (newRideStops['hour'] == h),\n",
    "#                 np.random.choice(distPickupWeekend['pickup_address'], p=distPickupWeekend['probabilities']),\n",
    "#                 newRideStops['pickup_address']\n",
    "#             )\n",
    "#         )\n",
    "#         # dropoff_address:\n",
    "#         newRideStops['dropoff_address'] = np.where(\n",
    "#             (newRideStops['workday'] == True)\n",
    "#             & (newRideStops['hour'] == h),\n",
    "#             np.random.choice(distDropoffWorkday['dropoff_address'], p=distDropoffWorkday['probabilities']),\n",
    "#             np.where(\n",
    "#                 (newRideStops['workday'] == False)\n",
    "#                 & (newRideStops['hour'] == h),\n",
    "#                 np.random.choice(distDropoffWeekend['dropoff_address'], p=distDropoffWeekend['probabilities']),\n",
    "#                 newRideStops['dropoff_address']\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     # Extract 'distance' and 'shortest_ridetime' based on generated routes\n",
    "#     newRideStops['distance'] = newRideStops.merge(routes, left_on=['pickup_address', 'dropoff_address'], right_on=['Start #', 'Ende #'], how='left')['Route [m]']\n",
    "#     newRideStops['shortest_ridetime'] = 1/(30 / (newRideStops['distance'] / 1000) )*60*60 # calculate shortest_ridetime in seconds with average speed of 30 km/h\n",
    "#     return newRideStops[['pickup_address', 'dropoff_address','distance', 'shortest_ridetime']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO: Check in the end if too many rides, which are too short or are not likely enough \n",
    "\n",
    "\n",
    "def generateRoute(oldRides, newRides, ridestops, routes):\n",
    "    # add route identifier to routes dataframe\n",
    "    allRoutes = routes[routes['Route [m]'] > 500] # Assumption: real rides are at least 500 m long\n",
    "    allRoutes['route'] = allRoutes['Start #'].astype(str) + \"-\" + allRoutes['Ende #'].astype(str)\n",
    "\n",
    "    # based on analysis of rides we distinguish between workdays (Monday till Friday noon) and weekend (Friday noon till Sunday)\n",
    "    newRideStops = pd.DataFrame(newRides[['created_at', 'scheduled_to', 'pickup_address', 'dropoff_address']], columns=['created_at', 'scheduled_to', 'pickup_address', 'dropoff_address'])\n",
    "    newRideStops['route'] = \"\"\n",
    "    newRideStops['day'] = newRideStops['scheduled_to'].apply(lambda x: dt.weekday(x))\n",
    "    newRideStops['hour'] = newRideStops['scheduled_to'].apply(lambda x: x.hour)\n",
    "    newRideStops['workday'] = np.where(\n",
    "        (\n",
    "            newRideStops['day'].isin([0,1,2,3,4]) # 0 = Monday, 6 = Sunday\n",
    "            & ~(\n",
    "                    (newRideStops['day'] == 4) \n",
    "                    & (newRideStops['hour'] > 13)\n",
    "            )\n",
    "        ),\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    oldRidestops = pd.DataFrame(oldRides[['state', 'scheduled_to', 'pickup_address', 'dropoff_address']], columns=['state', 'scheduled_to', 'pickup_address', 'dropoff_address'])\n",
    "    oldRidestops['route'] = oldRidestops['pickup_address'].astype(str) + \"-\" + oldRidestops['dropoff_address'].astype(str)\n",
    "    oldRidestops['scheduled_to'] = pd.to_datetime(oldRidestops['scheduled_to'])\n",
    "    oldRidestops['day'] = oldRidestops['scheduled_to'].apply(lambda x: dt.weekday(x))\n",
    "    oldRidestops['hour'] = oldRidestops['scheduled_to'].apply(lambda x: x.hour)\n",
    "    oldRidestops['workday'] = np.where(\n",
    "        (\n",
    "            oldRidestops['day'].isin([0,1,2,3,4]) # 0 = Monday, 6 = Sunday\n",
    "            & ~(\n",
    "                    (oldRidestops['day'] == 4) \n",
    "                    & (oldRidestops['hour'] > 13)\n",
    "            )\n",
    "        ),\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "    workdayOldRides = oldRidestops[(oldRidestops['workday']==True)]\n",
    "    weekendOldRides = oldRidestops[(oldRidestops['workday']==False)]\n",
    "\n",
    "    # generate ridestops\n",
    "    for h in [0] + list(range(7,24)): # rides start between 7:00 and 0:59\n",
    "        # timeframe used to get ridestop distribution\n",
    "        if h in [23,0]:\n",
    "            timeframe = [22,23,0]\n",
    "        elif h == 7:\n",
    "            timeframe = [7,8,9]\n",
    "        else:\n",
    "            timeframe = list(range(h-1,h+2))\n",
    "\n",
    "        ##### workday ridestop distribution #####\n",
    "        distWorkday = workdayOldRides[(workdayOldRides['hour'].isin(timeframe))]['route'].value_counts().rename_axis('route').reset_index(name='counts')\n",
    "        numberOfNoise = distWorkday['counts'].sum() / 80 * 20 # 20% noise\n",
    "        allRoutes['counts'] = distWorkday['counts'].min() # noise is weighted similar to least frequent real driven route\n",
    "        distWorkday = pd.concat([distWorkday, allRoutes[~allRoutes['route'].isin(distWorkday['route'])].sample(frac=1)[:int(numberOfNoise)][['route', 'counts']]])\n",
    "        distWorkday['probabilities'] = (distWorkday.counts / distWorkday.counts.sum())\n",
    "\n",
    "        ##### weekend ridestop distribution #####\n",
    "        distWeekend = weekendOldRides[(weekendOldRides['hour'].isin(timeframe))]['route'].value_counts().rename_axis('route').reset_index(name='counts')\n",
    "        numberOfNoise = distWeekend['counts'].sum() / 80 * 20 # 20% noise\n",
    "        allRoutes['counts'] = distWeekend['counts'].min() # noise is weighted similar to least frequent real driven route\n",
    "        distWeekend = pd.concat([distWeekend, allRoutes[~allRoutes['route'].isin(distWeekend['route'])].sample(frac=1)[:int(numberOfNoise)][['route', 'counts']]])\n",
    "        distWeekend['probabilities'] = (distWeekend.counts / distWeekend.counts.sum())\n",
    "\n",
    "        # split newRideStops dataframe in 1. ride-hour=h & weekend, 2. ride-hour=h & workday, 3. rest\n",
    "        newRideStops_h_wend = newRideStops[(newRideStops['hour']==h) & (newRideStops['workday']==False)]\n",
    "        newRideStops_h_work = newRideStops[(newRideStops['hour']==h) & (newRideStops['workday']==True)]\n",
    "        newRideStops_not_h = newRideStops[~((newRideStops['hour']==h) & (newRideStops['workday']==False)) & ~((newRideStops['hour']==h) & (newRideStops['workday']==True))]\n",
    "\n",
    "        # generate routes based on distributions\n",
    "        newRideStops_h_wend['route'] = np.random.choice(distWeekend['route'], p=distWeekend['probabilities'], size=newRideStops_h_wend.shape[0])\n",
    "        newRideStops_h_work['route'] = np.random.choice(distWorkday['route'], p=distWorkday['probabilities'], size=newRideStops_h_work.shape[0])\n",
    "\n",
    "        # concat 3 pieces back together\n",
    "        newRideStops = pd.concat([newRideStops_not_h, newRideStops_h_wend, newRideStops_h_work])\n",
    "\n",
    "    # Extract pickup & dropoff address from route column\n",
    "    newRideStops[['pickup_address', 'dropoff_address']] = newRideStops['route'].str.split('-', expand=True)\n",
    "    newRideStops['pickup_address'] = pd.to_numeric(newRideStops['pickup_address'])\n",
    "    newRideStops['dropoff_address'] = pd.to_numeric(newRideStops['dropoff_address'])\n",
    "\n",
    "    # Extract 'distance' and 'shortest_ridetime' based on generated routes\n",
    "    newRideStops['distance'] = newRideStops.merge(routes, left_on=['pickup_address', 'dropoff_address'], right_on=['Start #', 'Ende #'], how='left')['Route [m]']\n",
    "    newRideStops['shortest_ridetime'] = 1/(30 / (newRideStops['distance'] / 1000) )*60*60 # calculate shortest_ridetime in seconds with average speed of 30 km/h\n",
    "    newRideStops.sort_values(by=['created_at'])\n",
    "    return newRideStops[['pickup_address', 'dropoff_address','distance', 'shortest_ridetime']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generateRoute_simple2(oldRides, newRides, ridestops, routes):\n",
    "#     oldRideStops = oldRides[['pickup_address', 'dropoff_address']]\n",
    "#     oldRideStops['route'] = oldRideStops['pickup_address'].astype(str) + \"-\" + oldRideStops['dropoff_address'].astype(str)\n",
    "    \n",
    "#     dist = oldRideStops['route'].value_counts().rename_axis('route').reset_index(name='counts')\n",
    "#     dist['probabilities'] = (dist.counts / dist.counts.sum())\n",
    "\n",
    "#     newRideStops = pd.DataFrame(newRides[['pickup_address', 'dropoff_address']], columns=['pickup_address', 'dropoff_address'])\n",
    "#     newRideStops['route'] = np.random.choice(dist['route'], p=dist['probabilities'], size=newRides.shape[0])\n",
    "#     newRideStops[['pickup_address', 'dropoff_address']] = newRideStops['route'].str.split('-', expand=True)\n",
    "#     newRideStops['pickup_address'] = pd.to_numeric(newRideStops['pickup_address'])\n",
    "#     newRideStops['dropoff_address'] = pd.to_numeric(newRideStops['dropoff_address'])\n",
    "\n",
    "#     # Extract 'distance' and 'shortest_ridetime' based on generated routes\n",
    "#     newRideStops['distance'] = newRideStops.merge(routes, left_on=['pickup_address', 'dropoff_address'], right_on=['Start #', 'Ende #'], how='left')['Route [m]']\n",
    "#     newRideStops['shortest_ridetime'] = 1/(30 / (newRideStops['distance'] / 1000) )*60*60 # calculate shortest_ridetime in seconds with average speed of 30 km/h\n",
    "    \n",
    "#     return newRideStops[['pickup_address', 'dropoff_address','distance', 'shortest_ridetime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generateCreatedAt()\n",
    "- function that returns n random 'created_at' timestamps over a period of one specified month based on the probability distribution in original data \n",
    "- first step: choose a date from the month based on the probability distribution of rides over the weekdays (Monday-Sunday)\n",
    "- second step: choose a timestamp based on the probability distribution of rides that are on the same weekday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCreatedAt(oldRides, newRides, m, y):\n",
    "    # creat list with all days of the month to build up the probability distribution \n",
    "    if m == 12:\n",
    "        m1 = 1\n",
    "        y1 = y + 1\n",
    "    else:\n",
    "        m1 = m + 1\n",
    "        y1 = y\n",
    "    daydist = pd.DataFrame(pd.date_range(start=str(m)+'/01/'+str(y), end=str(m1)+'/01/'+str(y1),).to_pydatetime().tolist()[:-1], columns=['date'])\n",
    "    daydist['weekday'] = daydist['date'].apply(lambda x: dt.weekday(x)) # use the weekday distribution to represent real occurrences of rides\n",
    "\n",
    "    # extract all dates and their weekday, hour and minute \n",
    "    created = pd.DataFrame(pd.to_datetime(df['created_at']), columns=['created_at'])\n",
    "    created['day'] = created['created_at'].apply(lambda x: dt.weekday(x))\n",
    "    created['hour'] = created['created_at'].apply(lambda x: x.hour)\n",
    "    created['minute'] = created['created_at'].apply(lambda x: x.minute)\n",
    "    \n",
    "    # get the weekday distribution of old rides\n",
    "    dist_day = created['day'].value_counts().rename_axis('day').reset_index(name='counts')\n",
    "    dist_day['probabilities'] = (dist_day.counts / dist_day.counts.sum())\n",
    "    dist_day = dist_day.sort_values('day')\n",
    "\n",
    "    # get the hour distribution of old rides per weekday \n",
    "    dist_hour = []\n",
    "    for i in range(0,7):\n",
    "        dist_hour.append(created[created['day']==i]['hour'].value_counts().rename_axis('hour').reset_index(name='counts'))\n",
    "        dist_hour[i]['probabilities'] = (dist_hour[i].counts / dist_hour[i].counts.sum())\n",
    "        dist_hour[i] = dist_hour[i].sort_values('hour')\n",
    "\n",
    "    \n",
    "    # get the minute distribution of old rides\n",
    "    dist_minute = created['minute'].value_counts().rename_axis('minute').reset_index(name='counts')\n",
    "    dist_minute['probabilities'] = (dist_minute.counts / dist_minute.counts.sum())  \n",
    "    dist_minute = dist_minute.sort_values('minute')\n",
    "\n",
    "\n",
    "    # match probability that a ride is on that weekday to all dates in the simulated month\n",
    "    daydist['probabilities'] =  daydist['weekday'].apply(lambda x: dist_day[dist_day['day']==x]['probabilities'].values[0]) \n",
    "    daydist['probabilities'] = daydist['probabilities']/(daydist['probabilities'].sum()) # normalization neccessary to get probability distribution (sum of odds is 1)\n",
    "\n",
    "    # generate list of values\n",
    "    values = pd.DataFrame(np.random.choice(daydist['date'], p=daydist['probabilities'], size=newRides.shape[0]), columns=['created_at'])\n",
    "    values = values.sort_values('created_at')\n",
    "    values = values.reset_index()\n",
    "    values['day'] = values['created_at'].apply(lambda x: dt.weekday(x))\n",
    "    values['created_at'] = values['created_at'] + values['day'].apply(\n",
    "        lambda x: pd.Timedelta(\n",
    "            hours=np.random.choice(dist_hour[x]['hour'], p=dist_hour[x]['probabilities']), # choose hour based on distribution of that weekday\n",
    "            minutes=np.random.choice(dist_minute['minute'], p=dist_minute['probabilities']), # choose minute based on distribution of that hour\n",
    "            seconds=np.random.choice(list(range(0,60))) # random choice of seconds\n",
    "        )\n",
    "    )\n",
    "    values.sort_values(by=['created_at'])\n",
    "    return values['created_at']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generateScheduledTo()\n",
    "- function that returns n random 'scheduled_to' timestamps based on the probability distribution in original data \n",
    "- first, consider distribution of scheduled & immediate \n",
    "- second, for a scheduled ride add a random prebooking time (based on probability distribution of the prebooking time in original data) to created_at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateScheduledTo(oldRides, newRides):\n",
    "    scheduledNew = pd.DataFrame(columns=['hour'])\n",
    "    scheduledNew['created_at'] = newRides['created_at']\n",
    "    scheduledNew['hour'] = scheduledNew['created_at'].apply(lambda x: x.hour)\n",
    "\n",
    "    # get prebooking time\n",
    "    scheduled = pd.DataFrame(oldRides[['created_at', 'scheduled_to']], columns=['created_at', 'scheduled_to'])\n",
    "    scheduled['isScheduled'] = (scheduled.created_at != scheduled.scheduled_to)\n",
    "    scheduled['created_at'] = pd.to_datetime(scheduled['created_at'])\n",
    "    scheduled['scheduled_to'] = pd.to_datetime(scheduled['scheduled_to'])\n",
    "    scheduled['prebook_time'] = scheduled.scheduled_to - scheduled.created_at\n",
    "    scheduled['prebook_time'] = scheduled['prebook_time'].apply(lambda x: x.total_seconds())\n",
    "    \n",
    "    # distribution of prebooked and non-prebooked rides\n",
    "    dist = scheduled['isScheduled'].value_counts().rename_axis('isScheduled').reset_index(name='counts')\n",
    "    dist['probabilities'] = (dist.counts / dist.counts.sum())\n",
    "\n",
    "    # distribution of average prebook time \n",
    "    left_border = 8*60 # min value of 8 min -> assumption: scheduled ride must be at least 8 min in the future\n",
    "    dist_avg_prebook_time = getdistribution(scheduled[scheduled['isScheduled'] == True], 'prebook_time', min=left_border)\n",
    "\n",
    "    scheduledNew['scheduled_to'] = [(i + pd.Timedelta(dist_avg_prebook_time.rvs(1)[0], unit='seconds')).round(freq='10min') if np.random.choice(dist['isScheduled'], p=dist['probabilities']) else i for i, j in zip(scheduledNew.created_at, scheduledNew.hour)]\n",
    "    # we have no rides before 7\n",
    "    scheduledNew['hour'] = scheduledNew['scheduled_to'].apply(lambda x: x.hour)\n",
    "    scheduledNew['scheduled_to'] = [dt(i.year, i.month, i. day, 7, 0) if j in [1, 2, 3, 4, 5, 6] else i for i, j in zip(scheduledNew.scheduled_to, scheduledNew.hour)]\n",
    "    return scheduledNew['scheduled_to']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generateDispatchedAt()\n",
    "- function that returns n random 'dispatched_at' timestamps \n",
    "- case 1: scheduled ride -> dispatched_at = scheduled_at - 8 min\n",
    "- case 2: immediate ride -> dispatched_at = scheduled_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDispatchedAt(oldRides, newRides):\n",
    "    scheduled = pd.DataFrame(newRides[['created_at', 'scheduled_to']], columns=['created_at', 'scheduled_to'])\n",
    "    scheduled['isScheduled'] = (scheduled.created_at != scheduled.scheduled_to)\n",
    "    scheduled['created_at'] = pd.to_datetime(scheduled['created_at'])\n",
    "    scheduled['scheduled_to'] = pd.to_datetime(scheduled['scheduled_to'])\n",
    "    scheduled['dispatched_at'] = np.where(\n",
    "        scheduled['isScheduled']==True,\n",
    "        scheduled['scheduled_to'] - pd.Timedelta(minutes=8),\n",
    "        scheduled['scheduled_to']\n",
    "    )\n",
    "    return scheduled['dispatched_at']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generateArrival\n",
    "- function that returns n random timestamps for 'arriving_push', vehicle_arrived_at', 'pickup_arrival_time'\n",
    "- first, generate 'vehicle_arrived_at'\n",
    "    - for scheduled rides: scheduled_to + random scheduling deviation (based on probability distribution of scheduling_deviation=vehicle_arrived_at-scheduled_to in original data)\n",
    "    - for immediatie rides: scheduled_to + random pickup_arrival_time (based on probability distribution of pickup_arrival_time in original data)\n",
    "- second, calculate pickup_arrival_time=vehicle_arrived_at-dispatched_at\n",
    "- third, .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateArrival(oldRides, newRides):\n",
    "    # get needed information regarding the vehicle arrival in old data\n",
    "    arrivalOld = pd.DataFrame(oldRides[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at', 'pickup_arrival_time', 'arriving_push']], columns=['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at', 'pickup_arrival_time', 'arriving_push'])\n",
    "    arrivalOld['isScheduled'] = (arrivalOld.created_at != arrivalOld.scheduled_to)\n",
    "    arrivalOld['created_at'] = pd.to_datetime(arrivalOld['created_at'])\n",
    "    arrivalOld['scheduled_to'] = pd.to_datetime(arrivalOld['scheduled_to'])\n",
    "    arrivalOld['vehicle_arrived_at'] = pd.to_datetime(arrivalOld['vehicle_arrived_at'])\n",
    "    arrivalOld['arriving_push'] = pd.to_datetime(arrivalOld['arriving_push'])\n",
    "\n",
    "    # create dataframe with needed attributes to determine 'vehicle_arrived_at'\n",
    "    arrivalNew = pd.DataFrame(newRides[['created_at', 'scheduled_to', 'dispatched_at']], columns=['created_at', 'scheduled_to', 'dispatched_at'])\n",
    "    arrivalNew['isScheduled'] = (arrivalNew.created_at != arrivalNew.scheduled_to)\n",
    "    arrivalNew['created_at'] = pd.to_datetime(arrivalNew['created_at'])\n",
    "    arrivalNew['scheduled_to'] = pd.to_datetime(arrivalNew['scheduled_to'])\n",
    "    arrivalNew['dispatched_at'] = pd.to_datetime(arrivalNew['dispatched_at'])\n",
    "    \n",
    "    ##### generate timestamp 'vehicle_arrived_at' \n",
    "    arrivalOld['schedule_deviation'] = arrivalOld.apply(\n",
    "        lambda row: (\n",
    "            (row[\"vehicle_arrived_at\"] - row[\"scheduled_to\"] ).round(freq=\"s\")\n",
    "        ).total_seconds(),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # distribution over scheduled rides\n",
    "    left_border = -8*60 # min value of -8 minutes -> earliest arrived_at\n",
    "    dist_scheduledRides = getdistribution(arrivalOld[arrivalOld['isScheduled'] == True], 'schedule_deviation', min=left_border )\n",
    "\n",
    "    # distribution over instant rides - based on pickup_arrival_times distribution\n",
    "    left_border = 1 # min value of 1 second -> earliest arrived_at\n",
    "    dist_instantRides = getdistribution(arrivalOld[arrivalOld['isScheduled'] == False], 'pickup_arrival_time', min=left_border )\n",
    "\n",
    "\n",
    "    # determine timestamp 'vehicle_arrived_at' \n",
    "    arrivalNew['vehicle_arrived_at'] = arrivalNew.apply(\n",
    "        lambda row: (\n",
    "            (row[\"scheduled_to\"] + pd.Timedelta(dist_scheduledRides.rvs(1)[0], unit='seconds').round(freq=\"s\"))\n",
    "        )\n",
    "        if (row[\"isScheduled\"] == True)\n",
    "        else \n",
    "            (row[\"scheduled_to\"] + pd.Timedelta(dist_instantRides.rvs(1)[0], unit='seconds').round(freq=\"s\")),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    ##### calculate 'pickup_arrival_time'\n",
    "    arrivalNew[\"pickup_arrival_time\"] = (\n",
    "        arrivalNew[\"vehicle_arrived_at\"] - arrivalNew[\"dispatched_at\"]\n",
    "    ).dt.seconds\n",
    "\n",
    "    ##### generate arriving_push\n",
    "    # distribution of the time between arriving_push and vehicle_arrived_at\n",
    "    arrivalOld['deviation_of_arriving_push'] = arrivalOld.apply(\n",
    "        lambda row: (\n",
    "            (row[\"arriving_push\"] - row[\"vehicle_arrived_at\"] ).round(freq=\"s\")\n",
    "        ).total_seconds(),\n",
    "        axis=1,\n",
    "    )\n",
    "    dist = getdistribution(arrivalOld, 'deviation_of_arriving_push')\n",
    "\n",
    "    # determine timestamp 'arriving_push' \n",
    "    arrivalNew['arriving_push'] = arrivalNew.apply(\n",
    "        lambda row: (\n",
    "            (row[\"vehicle_arrived_at\"] + pd.Timedelta(dist.rvs(1)[0], unit='seconds').round(freq=\"s\"))\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # check that arriving_push is after dispatched_at  \n",
    "    arrivalNew['arriving_push'] = np.where(\n",
    "        arrivalNew['dispatched_at'] > arrivalNew['arriving_push'],\n",
    "        arrivalNew['dispatched_at'] + (arrivalNew['vehicle_arrived_at'] -  arrivalNew['dispatched_at']) * np.random.uniform(0.1,0.9),\n",
    "        arrivalNew['arriving_push']\n",
    "    )\n",
    "\n",
    "    return arrivalNew[['arriving_push', 'vehicle_arrived_at', 'pickup_arrival_time']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePickup(oldRides, newRides):\n",
    "    # get needed information regarding the pickup in old data\n",
    "    pickupOld = pd.DataFrame(oldRides[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at', 'pickup_at', 'pickup_first_eta', 'pickup_eta']], columns=['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at', 'pickup_at', 'pickup_first_eta', 'pickup_eta'])\n",
    "    pickupOld[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at', 'pickup_at', 'pickup_first_eta', 'pickup_eta']] = pickupOld[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at', 'pickup_at', 'pickup_first_eta', 'pickup_eta']].apply(pd.to_datetime)\n",
    "    pickupOld['isScheduled'] = (pickupOld.created_at != pickupOld.scheduled_to)\n",
    "\n",
    "    # create dataframe with needed attributes to determine pickup attributes\n",
    "    pickupNew = pd.DataFrame(newRides[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at']], columns=['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at'])\n",
    "    pickupNew['isScheduled'] = (pickupNew.created_at != pickupNew.scheduled_to)\n",
    "    pickupNew[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at']] = pickupNew[['created_at', 'scheduled_to', 'dispatched_at', 'vehicle_arrived_at']].apply(pd.to_datetime)\n",
    "    \n",
    "    ##### generate earliest_pickup_expectation\n",
    "    pickupNew['earliest_pickup_expectation'] = pickupNew['dispatched_at'] + pd.Timedelta(minutes=3)\n",
    "\n",
    "    ##### genrate pickup_at \n",
    "    pickupOld['time_until_pickup'] = pickupOld.apply(\n",
    "        lambda row: (\n",
    "            (row[\"pickup_at\"] - row[\"vehicle_arrived_at\"] ).round(freq=\"s\")\n",
    "        ).total_seconds(),\n",
    "        axis=1,\n",
    "    )\n",
    "    # distribution of the time a driver waits until pickup over scheduled rides\n",
    "    left_border = 1 # min value of 1 second -> earliest arrived_at\n",
    "    dist_scheduledRides = getdistribution(pickupOld[pickupOld['isScheduled'] == True], 'time_until_pickup', min=left_border )\n",
    "\n",
    "    # distribution of the time a driver waits until pickup over instant rides\n",
    "    left_border = 1 # min value of 1 second -> earliest arrived_at\n",
    "    dist_instantRides = getdistribution(pickupOld[pickupOld['isScheduled'] == False], 'time_until_pickup', min=left_border )\n",
    "\n",
    "    # determine timestamp 'pickup_at' \n",
    "    pickupNew['pickup_at'] = pickupNew.apply(\n",
    "        lambda row: (\n",
    "            (row[\"vehicle_arrived_at\"] + pd.Timedelta(dist_scheduledRides.rvs(1)[0], unit='seconds').round(freq=\"s\"))\n",
    "        )\n",
    "        if (row[\"isScheduled\"] == True)\n",
    "        else \n",
    "            (row[\"vehicle_arrived_at\"] + pd.Timedelta(dist_instantRides.rvs(1)[0], unit='seconds').round(freq=\"s\")),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    ##### generate pickup_first_eta\n",
    "    # distribution of the time between pickup_at and pickup_first_eta\n",
    "    pickupOld['deviation_of_pickup_first_eta'] = pickupOld.apply(\n",
    "        lambda row: (\n",
    "            (row[\"pickup_first_eta\"] - row[\"pickup_at\"] ).round(freq=\"s\")\n",
    "        ).total_seconds(),\n",
    "        axis=1,\n",
    "    )\n",
    "    dist = getdistribution(pickupOld, 'deviation_of_pickup_first_eta')\n",
    "\n",
    "    # determine timestamp 'pickup_first_eta' \n",
    "    pickupNew['pickup_first_eta'] = pickupNew.apply(\n",
    "        lambda row: (\n",
    "            (row[\"pickup_at\"] + pd.Timedelta(dist.rvs(1)[0], unit='seconds').round(freq=\"s\"))\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # check that pickup_first_eta is at least 3 min. after created_at \n",
    "    pickupNew['pickup_first_eta'] = np.where(\n",
    "        (pickupNew['created_at'] + pd.Timedelta(minutes=3)) > pickupNew['pickup_first_eta'],\n",
    "        pickupNew['created_at'] + pd.Timedelta(minutes=3), # created_at + 3 min. is minimum\n",
    "        pickupNew['pickup_first_eta']\n",
    "    )\n",
    "    # check that pickup_first_eta is after dispatched_at \n",
    "    pickupNew['pickup_first_eta'] = np.where(\n",
    "        pickupNew['dispatched_at'] > pickupNew['pickup_first_eta'],\n",
    "        pickupNew['dispatched_at'] + pd.Timedelta(minutes=3), # TODO: mehr randomness? \n",
    "        pickupNew['pickup_first_eta']\n",
    "    )\n",
    "\n",
    "    ##### generate pickup_eta\n",
    "    # distribution of the time between pickup_at and pickup_eta\n",
    "    pickupOld['deviation_of_pickup_eta'] = pickupOld.apply(\n",
    "        lambda row: (\n",
    "            (row[\"pickup_eta\"] - row[\"pickup_at\"] ).round(freq=\"s\")\n",
    "        ).total_seconds(),\n",
    "        axis=1,\n",
    "    )\n",
    "    dist = getdistribution(pickupOld, 'deviation_of_pickup_eta')\n",
    "\n",
    "    # determine timestamp 'pickup_eta' \n",
    "    pickupNew['pickup_eta'] = pickupNew.apply(\n",
    "        lambda row: (\n",
    "            (row[\"pickup_at\"] + pd.Timedelta(dist.rvs(1)[0], unit='seconds').round(freq=\"s\"))\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # check that pickup_eta is after dispatched_at  \n",
    "    pickupNew['pickup_eta'] = np.where(\n",
    "        pickupNew['dispatched_at'] > pickupNew['pickup_eta'],\n",
    "        pickupNew['dispatched_at'] + pd.Timedelta(minutes=3), #TODO: mehr randomness\n",
    "        pickupNew['pickup_eta']\n",
    "    )\n",
    "\n",
    "    return pickupNew[['earliest_pickup_expectation', 'pickup_at', 'pickup_eta', 'pickup_first_eta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDropoff(oldRides, newRides, routes):\n",
    "    # get needed information regarding the dropoff in old data\n",
    "    dropoffOld = pd.DataFrame(oldRides[['pickup_address', 'dropoff_address', 'scheduled_to', 'dropoff_at', 'dropoff_first_eta', 'dropoff_eta', 'ride_time']], columns=['pickup_address', 'dropoff_address', 'scheduled_to', 'dropoff_at', 'dropoff_first_eta', 'dropoff_eta', 'ride_time'])\n",
    "    dropoffOld[['scheduled_to', 'dropoff_at', 'dropoff_first_eta', 'dropoff_eta']] = dropoffOld[['scheduled_to', 'dropoff_at', 'dropoff_first_eta', 'dropoff_eta']].apply(pd.to_datetime)\n",
    "    dropoffOld['day'] = dropoffOld['scheduled_to'].apply(lambda x: dt.weekday(x))\n",
    "    dropoffOld['hour'] = dropoffOld['scheduled_to'].apply(lambda x: x.hour)\n",
    "    dropoffOld['workday'] = np.where(\n",
    "        (\n",
    "            dropoffOld['day'].isin([0,1,2,3,4]) # 0 = Monday, 6 = Sunday\n",
    "            & ~(\n",
    "                    (dropoffOld['day'] == 4) \n",
    "                    & (dropoffOld['hour'] > 13)\n",
    "            )\n",
    "        ),\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    # create dataframe with needed attributes to determine dropoff attributes\n",
    "    dropoffNew = pd.DataFrame(newRides[['pickup_address', 'dropoff_address', 'scheduled_to', 'pickup_at', 'pickup_first_eta', 'pickup_eta', 'shortest_ridetime']], columns=['pickup_address', 'dropoff_address', 'scheduled_to', 'pickup_at', 'pickup_first_eta', 'pickup_eta', 'shortest_ridetime'])\n",
    "    dropoffNew[['scheduled_to', 'pickup_at', 'pickup_first_eta', 'pickup_eta']] = dropoffNew[['scheduled_to', 'pickup_at', 'pickup_first_eta', 'pickup_eta']].apply(pd.to_datetime)\n",
    "    dropoffNew['day'] = dropoffNew['scheduled_to'].apply(lambda x: dt.weekday(x))\n",
    "    dropoffNew['hour'] = dropoffNew['scheduled_to'].apply(lambda x: x.hour)\n",
    "    dropoffNew['timeframe'] = dropoffNew['hour'].apply(\n",
    "        lambda h: (\n",
    "            [22,23,0]\n",
    "            if h in [23,0]\n",
    "            else \n",
    "            ([7,8,9]\n",
    "            if h == 7\n",
    "            else\n",
    "            list(range(h-1,h+2))) \n",
    "            )\n",
    "    )\n",
    "    dropoffNew['workday'] = np.where(\n",
    "        (\n",
    "            dropoffNew['day'].isin([0,1,2,3,4]) # 0 = Monday, 6 = Sunday\n",
    "            & ~(\n",
    "                    (dropoffNew['day'] == 4) \n",
    "                    & (dropoffNew['hour'] > 13)\n",
    "            )\n",
    "        ),\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    ##### generate ride_time based on ride_time of most similar rides\n",
    "    dropoffNew['ride_time'] = dropoffNew.apply(\n",
    "        lambda row:\n",
    "            # if rides exist with same route & workday/weekend flag & in a timeframe of +/-1 hour\n",
    "            round(dropoffOld[(dropoffOld['pickup_address']==row['pickup_address']) \n",
    "                & (dropoffOld['dropoff_address']==row['dropoff_address'])\n",
    "                & (dropoffOld['workday']==row['workday'])          \n",
    "                & (dropoffOld['hour'].isin(row['timeframe']))]['ride_time'].mean())\n",
    "            if len(dropoffOld[(dropoffOld['pickup_address']==row['pickup_address']) \n",
    "                & (dropoffOld['dropoff_address']==row['dropoff_address'])\n",
    "                & (dropoffOld['workday']==row['workday'])                   \n",
    "                & (dropoffOld['hour'].isin(row['timeframe']))]['ride_time']) > 0\n",
    "            else\n",
    "            # if rides exist with same route & in a timeframe of +/-1 hour - workday/weekend does not matter\n",
    "            round(dropoffOld[(dropoffOld['pickup_address']==row['pickup_address']) \n",
    "                & (dropoffOld['dropoff_address']==row['dropoff_address'])\n",
    "                & (dropoffOld['hour'].isin(row['timeframe']))]['ride_time'].mean())\n",
    "            if len(dropoffOld[(dropoffOld['pickup_address']==row['pickup_address']) \n",
    "                & (dropoffOld['dropoff_address']==row['dropoff_address'])\n",
    "                & (dropoffOld['hour'].isin(row['timeframe']))]['ride_time']) > 0\n",
    "            else\n",
    "            # if rides exist with same route - day & hour does not matter\n",
    "            round(dropoffOld[(dropoffOld['pickup_address']==row['pickup_address']) \n",
    "                & (dropoffOld['dropoff_address']==row['dropoff_address'])]['ride_time'].mean())\n",
    "            if len(dropoffOld[(dropoffOld['pickup_address']==row['pickup_address']) \n",
    "                & (dropoffOld['dropoff_address']==row['dropoff_address'])]['ride_time']) > 0\n",
    "            else\n",
    "            # else, use shortest ridetime: 30km/h over distance of the route\n",
    "            round((routes[(routes['Start #']==row['pickup_address']) \n",
    "                & (routes['Ende #']==row['dropoff_address'])]['Route [m]'].values[0] * 3600 / 30000) * np.random.uniform(1.0,1.2)),\n",
    "            axis=1,\n",
    "    )\n",
    "\n",
    "    ##### genereate dropoff_at \n",
    "    dropoffNew['dropoff_at'] = dropoffNew['pickup_at'] + pd.to_timedelta(dropoffNew['ride_time'], unit='seconds')\n",
    "\n",
    "    ##### generate dropoff_first_eta\n",
    "    dropoffNew['dropoff_first_eta'] = dropoffNew['pickup_first_eta'] + pd.to_timedelta(dropoffNew['shortest_ridetime'], unit='seconds')\n",
    "\n",
    "    ##### generate dropoff_eta\n",
    "    # distribution of the time between dropoff_at and dropoff_eta\n",
    "    dropoffOld['deviation_of_dropoff_eta'] = dropoffOld.apply(\n",
    "        lambda row: (\n",
    "            (row[\"dropoff_eta\"] - row[\"dropoff_at\"] ).round(freq=\"s\")\n",
    "        ).total_seconds(),\n",
    "        axis=1,\n",
    "    )\n",
    "    dist = getdistribution(dropoffOld, 'deviation_of_dropoff_eta')\n",
    "\n",
    "    # determine timestamp 'dropoff_eta' \n",
    "    dropoffNew['dropoff_eta'] = dropoffNew.apply(\n",
    "        lambda row: (\n",
    "            (row[\"dropoff_at\"] + pd.Timedelta(dist.rvs(1)[0], unit='seconds').round(freq=\"s\"))\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # check that dropoff_eta is after pickup_eta & pickup_at\n",
    "    dropoffNew['dropoff_eta'] = np.where(\n",
    "        (dropoffNew['pickup_eta'] > dropoffNew['dropoff_eta'])\n",
    "        | (dropoffNew['pickup_at'] > dropoffNew['dropoff_eta']),\n",
    "        dropoffNew['dropoff_at'] + pd.Timedelta(minutes=3), # TODO: mehr randomness\n",
    "        dropoffNew['dropoff_eta']\n",
    "    )\n",
    "\n",
    "\n",
    "    return dropoffNew[['dropoff_at', 'dropoff_eta', 'dropoff_first_eta']]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generateValues()\n",
    "- general function that returns n random values based on the probability distribution of a certain column\n",
    "- used for the following ride attributes: number_of_passenger, free_ride, payment_type, arrival_indicator, rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateValues(column_name, df, newRides):\n",
    "    dist = df[column_name].value_counts().rename_axis(column_name).reset_index(name='counts')\n",
    "    dist['probabilities'] = (dist.counts / dist.counts.sum())\n",
    "    return np.random.choice(dist[column_name], p=dist['probabilities'], size=newRides.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes: ['pickup_arrival_time', 'arrival_deviation', 'waiting_time', 'boarding_time', 'ride_time', 'trip_time', 'shortest_ridetime', 'delay', 'longer_route_factor']\n",
    "def generateTimeperiods(newRides):\n",
    "    # Attribute: 'arrival_deviation'\n",
    "    newRides[\"arrival_deviation\"] = newRides.apply(\n",
    "        lambda row: (\n",
    "            (row[\"vehicle_arrived_at\"] - row[\"arriving_push\"]).round(freq=\"s\")\n",
    "        ).total_seconds()\n",
    "        - 180\n",
    "        if (row[\"vehicle_arrived_at\"] == row[\"vehicle_arrived_at\"])\n",
    "        and (row[\"arriving_push\"] == row[\"arriving_push\"])\n",
    "        else np.NaN,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Attribute: 'waiting_time'\n",
    "    newRides[\"waiting_time\"] = newRides.apply(\n",
    "        lambda row: (\n",
    "            (row[\"vehicle_arrived_at\"] - row[\"earliest_pickup_expectation\"]).round(\n",
    "                freq=\"s\"\n",
    "            )\n",
    "        ).total_seconds()\n",
    "        if (row[\"vehicle_arrived_at\"] == row[\"vehicle_arrived_at\"])\n",
    "        and (row[\"earliest_pickup_expectation\"] == row[\"earliest_pickup_expectation\"])\n",
    "        else np.NaN,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Attribute: 'boarding_time'\n",
    "    newRides[\"boarding_time\"] = newRides.apply(\n",
    "        lambda row: (\n",
    "            (row[\"pickup_at\"] - row[\"vehicle_arrived_at\"]).round(freq=\"s\")\n",
    "        ).total_seconds()\n",
    "        if (row[\"vehicle_arrived_at\"] == row[\"vehicle_arrived_at\"])\n",
    "        and (row[\"pickup_at\"] == row[\"pickup_at\"])\n",
    "        else np.NaN,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Attribute: 'ride_time'\n",
    "    newRides[\"ride_time\"] = newRides.apply(\n",
    "        lambda row: (\n",
    "            (row[\"dropoff_at\"] - row[\"pickup_at\"]).round(freq=\"s\")\n",
    "        ).total_seconds()\n",
    "        if (row[\"dropoff_at\"] == row[\"dropoff_at\"])\n",
    "        and (row[\"pickup_at\"] == row[\"pickup_at\"])\n",
    "        else np.NaN,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Attribute: 'trip_time'\n",
    "    newRides[\"trip_time\"] = newRides.apply(\n",
    "        lambda row: (row[\"ride_time\"] + row[\"waiting_time\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Attribute: 'delay'\n",
    "    newRides[\"delay\"] = newRides.apply(\n",
    "        lambda row: (row[\"trip_time\"] - row[\"shortest_ridetime\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Attribute: 'longer_route_factor'\n",
    "    newRides[\"longer_route_factor\"] = newRides.apply(\n",
    "        lambda row: round(row[\"ride_time\"] / row[\"shortest_ridetime\"], 2)\n",
    "        if (row[\"shortest_ridetime\"] != 0)\n",
    "        else np.NaN,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return newRides[['arrival_deviation', 'waiting_time', 'boarding_time', 'ride_time', 'trip_time', 'delay', 'longer_route_factor']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRideSpecs(oldRides,ridestops, routes, n, month, year):\n",
    "    timestamp = str(round(time.time()))\n",
    "    newRides = pd.DataFrame(columns=oldRides.columns)\n",
    "    oldRides = oldRides[oldRides['state']=='completed']\n",
    "    newRides['id'] = [timestamp + '-' + str(x) for x in list(range(0,n))]\n",
    "    newRides['user_id'] = [str(x) + '-' + timestamp for x in list(range(0,n))] # Ein Kunde mehrere Rides\n",
    "    newRides['number_of_passenger'] = generateValues('number_of_passenger', oldRides, newRides)\n",
    "    newRides['free_ride'] = generateValues('free_ride', oldRides, newRides)\n",
    "    newRides['payment_type'] = generateValues('payment_type', oldRides, newRides)\n",
    "    newRides['state'] = 'completed'\n",
    "    newRides['arrival_indicator'] = generateValues('arrival_indicator', oldRides, newRides)\n",
    "    newRides['rating'] = generateValues('rating', oldRides, newRides) #zufällig ratings rein, die nicht bisher gerated wurden? Oder Rating ganz raus?\n",
    "    newRides['created_at'] = generateCreatedAt(oldRides, newRides, month, year)\n",
    "    newRides['scheduled_to'] = generateScheduledTo(oldRides, newRides)\n",
    "    newRides[['pickup_address', 'dropoff_address','distance', 'shortest_ridetime']] = generateRoute(oldRides, newRides, ridestops, routes) # prices are not considered\n",
    "    # newRides[['pickup_address', 'dropoff_address','distance', 'shortest_ridetime']] = generateRoute_simple(oldRides, newRides, ridestops, routes) # prices are not considered\n",
    "    # newRides[['pickup_address', 'dropoff_address','distance', 'shortest_ridetime']] = generateRoute_simple2(oldRides, newRides, ridestops, routes) # prices are not considered\n",
    "    newRides['dispatched_at'] = generateDispatchedAt(oldRides, newRides)\n",
    "    newRides[['arriving_push','vehicle_arrived_at', 'pickup_arrival_time']] = generateArrival(oldRides, newRides)\n",
    "    newRides[['earliest_pickup_expectation', 'pickup_at', 'pickup_eta', 'pickup_first_eta']] = generatePickup(oldRides, newRides)\n",
    "    newRides[['dropoff_at', 'dropoff_eta', 'dropoff_first_eta']] = generateDropoff(oldRides, newRides, routes)\n",
    "    newRides[['arrival_deviation', 'waiting_time', 'boarding_time', 'ride_time', 'trip_time', 'delay', 'longer_route_factor']] = generateTimeperiods(newRides)\n",
    "    return newRides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRides = pd.DataFrame(columns=df.columns)\n",
    "warnings.filterwarnings('ignore')\n",
    "newRides = generateRideSpecs(df, df_stops, df_routes, 9002, 6, 2022)\n",
    "newRides[['arriving_push', 'vehicle_arrived_at', 'created_at', 'scheduled_to', 'dispatched_at','vehicle_arrived_at', 'pickup_arrival_time', 'dropoff_at', 'dropoff_eta', 'pickup_first_eta', 'shortest_ridetime']].head(10)\n",
    "\n",
    "\n",
    "# TODO: arrived_at darf nicht vor dispatched_at liegen \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRides.to_excel(\"simulated.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completed = df[df['state']=='completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRides[newRides['earliest_pickup_expectation'] > newRides['dropoff_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_completed[df_completed['earliest_pickup_expectation'] > df_completed['dropoff_at']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completed[['arriving_push', 'vehicle_arrived_at', 'created_at', 'scheduled_to', 'pickup_at', 'pickup_first_eta', 'pickup_eta']] = df_completed[['arriving_push', 'vehicle_arrived_at', 'created_at', 'scheduled_to', 'pickup_at', 'pickup_first_eta', 'pickup_eta']].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completed[(df_completed['scheduled_to'] > df_completed['pickup_eta'] ) ]#& (df_completed['dropoff_address'] == 3012)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_completed['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         NaN\n",
       "2         1.0\n",
       "3         NaN\n",
       "4         NaN\n",
       "         ... \n",
       "18957    31.0\n",
       "18958     NaN\n",
       "18959     5.0\n",
       "18960     2.0\n",
       "18961    20.0\n",
       "Name: vehicle_arrived_at, Length: 18961, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['vehicle_arrived_at']).dt.day"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "453e59b997346832b8b464675f5c42a6d022616f3d6473b0c2c540035952836d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
